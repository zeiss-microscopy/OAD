{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cHZX_QBJAsxR",
    "outputId": "81d368f6-4b14-479c-cf2f-12574f460fe9",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Install czmodel and dependencies\n",
    "! pip install --upgrade pip|\n",
    "! pip install \"czmodel>=3.0,<3.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XCOyzv2frEEE"
   },
   "outputs": [],
   "source": [
    "# This can be used to switch on/off warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QqfOr73SrEEE"
   },
   "source": [
    "# Simple TF2 + Keras model for regression (to denoise the image)\n",
    "This notebook shows the entire workflow of training an ANN with [TensorFlow 2](https://www.tensorflow.org/) using the Keras API and exporting the trained model to the [CZANN format](https://pypi.org/project/czmodel/) to be ready for use within the [Intellesis](https://www.zeiss.de/mikroskopie/produkte/mikroskopsoftware/zen-intellesis-image-segmentation-by-deep-learning.html) infrastructure.\n",
    "\n",
    "* The trained model is rather simple (for demo purposes) and trained on a small test dataset.\n",
    "* **Therefore, this notebook is meant to be understood as a guide for exporting trained models.**\n",
    "* **The notebook does not provide instructions how to train a model correctly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BHRgA5LrEEE"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rV-5PAIarEEF"
   },
   "outputs": [],
   "source": [
    "# Required imports to train a simple TF2 + Keras model for regression and package it as CZANN.\n",
    "# The CZANN can then be imported in ZEN and used for regression workflows (e.g. denoising).\n",
    "\n",
    "# General imports\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Function provided by the PyPI package called czmodel (by ZEISS)\n",
    "from czmodel.model_metadata import ModelMetadata, ModelSpec, ModelType\n",
    "from czmodel import DefaultConverter\n",
    "from czmodel.util.transforms import Shift, Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g5JozIXsrEEF",
    "outputId": "72d540f7-4301-4b79-d79f-affeeb771bf6",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Optional: suppress TF warnings\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "print(tf.__version__)\n",
    "print(tf.version.GIT_VERSION, tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DdhLWPEPrEEF"
   },
   "source": [
    "## Training Pipeline\n",
    "This section describes a simple training procedure that creates a trained Keras model.\n",
    "\n",
    "* Therefore, it only represents the custom training procedure\n",
    "* Such procedure will vary from case to case and will contain more sophisticated ways to generate an optimized Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BIyRQoWrEEF"
   },
   "source": [
    "### Define parameters for data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BoxrbCmwrEEF"
   },
   "outputs": [],
   "source": [
    "# Folder containing the input images\n",
    "IMAGES_FOLDER = 'Mouse_Kidney_images/images/'\n",
    "\n",
    "# Folder containing the ground truth regression labels\n",
    "# Regression labels contain a real number for each pixel\n",
    "LABELS_FOLDER = 'Mouse_Kidney_images/labels/'\n",
    "\n",
    "# Path to the data on GitHub\n",
    "GITHUB_TRAINING_DATA_PATH = 'https://raw.githubusercontent.com/zeiss-microscopy/OAD/master/Machine_Learning/notebooks/czmodel/Mouse_Kidney_images.zip' # TODO: Update this path\n",
    "GITHUB_MODEL_CONVERSION_SPEC_PATH = 'https://raw.githubusercontent.com/zeiss-microscopy/OAD/master/Machine_Learning/notebooks/czmodel/regression_conversion_spec.json' # TODO Update this path\n",
    "\n",
    "# Define the number of input color channels\n",
    "# This means that the inputs are grayscale with one channel only\n",
    "CHANNELS = 1 \n",
    "\n",
    "# The size of image crops to train the model with\n",
    "CROP_SIZE = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JUvTmdVrEEF"
   },
   "source": [
    "### Download data if it's not available on disk\n",
    "If this notebook is run e.g. as a colab notebook, it does not have access to the data folder on gitub via disk access. \n",
    "In that case we need to download the data from github first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6v-O_KWTNpck",
    "outputId": "ba259be4-c149-43e1-9422-7dcbcd7fb48c",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LKeWmEpSrEEF"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Download training data\n",
    "if not (os.path.isdir(IMAGES_FOLDER) and os.path.isdir(LABELS_FOLDER)):\n",
    "    compressed_data = './Mouse_Kidney_images.zip'\n",
    "    if not os.path.isfile(compressed_data):\n",
    "        import io\n",
    "        response = requests.get(GITHUB_TRAINING_DATA_PATH, stream=True)\n",
    "        compressed_data = io.BytesIO(response.content)\n",
    "        \n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(compressed_data, 'r') as zip_accessor:\n",
    "        zip_accessor.extractall('./')\n",
    "        \n",
    "# Download model conversion spec\n",
    "if not os.path.isfile('regression_conversion_spec.json'):\n",
    "    response = requests.get(GITHUB_MODEL_CONVERSION_SPEC_PATH, stream=True)\n",
    "    with open('regression_conversion_spec.json', 'wb') as handle:\n",
    "        handle.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "euca9cyIrEEF"
   },
   "source": [
    "### Read images\n",
    "This part contains the logic to read pairs of images and label masks for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6_mcpDgrEEF"
   },
   "outputs": [],
   "source": [
    "# Determine the paths of the input samples\n",
    "sample_images = sorted([os.path.join(IMAGES_FOLDER, f) for f in os.listdir(IMAGES_FOLDER) \n",
    "                        if os.path.isfile(os.path.join(IMAGES_FOLDER, f))])\n",
    "\n",
    "# Determine the paths of the corresponding labels\n",
    "sample_labels = sorted([os.path.join(LABELS_FOLDER, f) for f in os.listdir(LABELS_FOLDER) \n",
    "                       if os.path.isfile(os.path.join(LABELS_FOLDER, f))])\n",
    "\n",
    "# Load images as numpy arrays and scale to interval [0..1]\n",
    "images_loaded = np.asarray(\n",
    "    [\n",
    "        tf.image.decode_image(\n",
    "            tf.io.read_file(sample_path), channels=CHANNELS, dtype=tf.uint16\n",
    "        ).numpy().astype(np.float32) / (2**16 - 1)\n",
    "        for sample_path in sample_images\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load the labels as numpy arrays and scale to interval [0..1]\n",
    "labels_loaded = np.asarray([\n",
    "    tf.image.decode_image(\n",
    "            tf.io.read_file(sample_path), channels=CHANNELS, dtype=tf.uint8\n",
    "        ).numpy().astype(np.float32) / (2**8 - 1)\n",
    "        for sample_path in sample_labels\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "esyVCW_WrEEF"
   },
   "outputs": [],
   "source": [
    "# Normalize images\n",
    "images_mean = images_loaded.mean(axis=(0,1,2))\n",
    "images_std = images_loaded.std(axis=(0,1,2))\n",
    "images_loaded = (images_loaded - images_mean) / images_std\n",
    "\n",
    "# Normalize labels\n",
    "labels_loaded = (labels_loaded - images_mean) / images_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9B-lhwXrEEG"
   },
   "source": [
    "### Define a TensorFlow dataset to pre-process the images\n",
    "Since the dataset contains very large images we need to train on smaller crops in order to not exhaust the GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hrIPBmrkrEEG"
   },
   "outputs": [],
   "source": [
    "# Define a simple random crop transformation to train on smaller crops\n",
    "def random_crop(image, mask, height, width):\n",
    "    stacked = tf.concat([image, mask], axis=-1)\n",
    "    stacked_cropped = tf.image.random_crop(\n",
    "        stacked,\n",
    "        size=tf.stack([height, width, tf.shape(image)[-1] + tf.shape(mask)[-1]], axis=0)\n",
    "    )\n",
    "    image_cropped = stacked_cropped[..., :tf.shape(image)[-1]]\n",
    "    mask_cropped = stacked_cropped[..., tf.shape(image)[-1]:]\n",
    "    return image_cropped, mask_cropped\n",
    "\n",
    "# Define a TensorFlow dataset applying the random crop and batching the training data.\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    ((images_loaded, labels_loaded))\n",
    ").map(\n",
    "    lambda x, y: random_crop(x, y, CROP_SIZE, CROP_SIZE)\n",
    ").shuffle(10).batch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRujNv7nrEEG"
   },
   "source": [
    "### Define a simple model\n",
    "This part defines a simple Keras convolutional model for regression task. It is also possible to add pre-processing layers to the model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prtTh7t2ZubC"
   },
   "outputs": [],
   "source": [
    "# Define simple Keras convolutional model\n",
    "model = tf.keras.models.Sequential(\n",
    "    [   # Encoder\n",
    "        tf.keras.layers.Conv2D(16, 1, activation=\"linear\", padding=\"same\"),\n",
    "        tf.keras.layers.MaxPooling2D(2, padding=\"same\"),\n",
    "        tf.keras.layers.Conv2D(16, 1, activation=\"linear\", padding=\"same\"),\n",
    "        tf.keras.layers.MaxPooling2D(2, padding=\"same\"),\n",
    "        tf.keras.layers.Conv2D(16, 1, activation=\"linear\", padding=\"same\"),\n",
    "        # Decoder\n",
    "        tf.keras.layers.UpSampling2D(2, interpolation = 'bilinear'),\n",
    "        tf.keras.layers.Conv2D(16, 1, activation=\"linear\", padding=\"same\"),\n",
    "        tf.keras.layers.UpSampling2D(2, interpolation = 'bilinear'), \n",
    "        tf.keras.layers.Conv2D(1, 3, activation=\"selu\", padding=\"same\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdaAOFWxrEEG"
   },
   "source": [
    "### Fit the model to the loaded data\n",
    "This part fits the model to the loaded data. In this test example we do not care about an actual evaluation of the model using validation and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99kOKKv4tJOK"
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  plt.plot(history.history['loss'])\n",
    "  plt.title('training loss')\n",
    "  plt.ylabel('loss')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hY5nMzGVrEEG",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "81245272-1cca-4812-ce96-e966f40d909d",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Define number of training epochs\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "# Fit the model to the data\n",
    "history = model.fit(dataset, epochs=NUM_EPOCHS)\n",
    "\n",
    "# Plot the training history\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cgU2oygWyBVC",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "outputId": "080cdba2-66c0-4263-cd83-af1a1cd74c12",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Plot the training results\n",
    "images_labels  = next(iter(dataset))\n",
    "image = images_labels[0][0]\n",
    "label = images_labels[1][0]\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "# Plot the inputs\n",
    "plt.subplot(1,3,1)\n",
    "plt.axis('off')\n",
    "plt.title('Inputs')\n",
    "plt.imshow(image[:,:,0], cmap='gray')\n",
    "\n",
    "# Plot the predictions\n",
    "prediction = model.predict(image)\n",
    "plt.subplot(1,3,2)\n",
    "plt.axis('off')\n",
    "plt.title('Predictions')\n",
    "plt.imshow(prediction[:,:,0,0], cmap='gray')\n",
    "\n",
    "# Plot the ground truth labels\n",
    "plt.subplot(1,3,3)\n",
    "plt.axis('off')\n",
    "plt.title('Ground truth labels')\n",
    "plt.imshow(label[:,:,0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvLa6DMdrEEG"
   },
   "source": [
    "## Create a CZANN from the trained Keras model\n",
    "In this section we export the trained model to the CZANN format using the czmodel library and some additional meta data all possible parameter choices are described in the [ANN model specification](https://pypi.org/project/czmodel/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JtOarJOrEEG"
   },
   "source": [
    "### Define Meta Data\n",
    "We first define the meta data needed to run the model within the Intellesis infrastructure. The `czmodel` package offers a named tuple `ModelMetadata` that allows to either parse as JSON file as described in the [specification document](https://pypi.org/project/czmodel/) or to directly specify the parameters as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kIoXhHQrEEG"
   },
   "source": [
    "### Create a Model Specification Object\n",
    "The export functions provided by the `czmodel` package expect a `ModelSpec` tuple that features the Keras model to be exported, the corresponding model meda data and optionally a license file for the model.\n",
    "\n",
    "Therefore, we wrap our model and the `model_metadata` instance into a `ModelSpec` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OHmyTPUsrEEG"
   },
   "outputs": [],
   "source": [
    "# Define dimensions - ZEN Intellesis requires fully defined spatial dimensions in the meta data of the CZANN model.\n",
    "# The ZEN TilingClient uses the input shape in the meta data to infer the tile size to pass an image to the inferencer.\n",
    "# Important: The tile size has to be chosen s.t. inference is possible with the minimum hardware requirements of Intellesis\n",
    "# Optional: Define target spatial dimensions of the model for inference.\n",
    "input_size = 1024\n",
    "\n",
    "# Define the model metadata\n",
    "model_metadata = ModelMetadata(\n",
    "    input_shape=[input_size, input_size, CHANNELS],\n",
    "    output_shape=[input_size, input_size, CHANNELS],\n",
    "    model_type=ModelType.REGRESSION,\n",
    "    model_name=\"Simple_Kidney_RegressionModel\",\n",
    "    min_overlap=[8, 8],\n",
    ")\n",
    "\n",
    "model_spec = ModelSpec(\n",
    "    model=model,\n",
    "    model_metadata=model_metadata,\n",
    "    license_file=None\n",
    ")\n",
    "\n",
    "# Define pre-processing\n",
    "preprocessing = [\n",
    "    Shift(-images_mean),\n",
    "    Scale(1.0 / images_std)\n",
    "]\n",
    "\n",
    "# Define post-processing\n",
    "postprocessing = [\n",
    "    Scale(images_std),\n",
    "    Shift(images_mean)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oh92i7lCrEEH"
   },
   "source": [
    "### Perform model export into *.czann  file format\n",
    "\n",
    "The converters from the `czmodel` library offers two functions to perform the actual export. \n",
    "\n",
    "* `convert_from_json_spec` allows to provide a JSON file containing all the information of a ModelSpec object and converts a model in SavedModel format on disk to a `.czann` file that can be loaded with ZEN.\n",
    "* `convert_from_model_spec` expects a `ModelSpec` object, an output path and name and optionally target spatial dimensions for the expected input of the exported model. From this information it creates a `.czann`  file containing the specified model.\n",
    "\n",
    "Currently, `czmodel` offers one converter for a regression model:\n",
    "* DefaultConverter: Converts a model to a *.czann file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jBMuGY9OrEEH",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "dfeeb442-b106-4e35-c374-3b7add988be7",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "DefaultConverter().convert_from_model_spec(\n",
    "    model_spec=model_spec, \n",
    "    output_path='./', \n",
    "    output_name='simple_kidney_regmodel',\n",
    "    spatial_dims=(input_size, input_size),\n",
    "    preprocessing=preprocessing,\n",
    "    postprocessing=postprocessing\n",
    ")\n",
    "\n",
    "# In the example above there will be a \"\"./czmodel_output/simple_kidney_regmodel.czann\" file saved on disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSNuJXv5rEEH"
   },
   "source": [
    "## Remarks\n",
    "The generated .czann file can be directly loaded into ZEN Intellesis to perform regression tasks with the trained model.\n",
    "If there is already a trained model in SavedModel format present on disk, it can also be converted by providing the path to the saved model directory instead of a Keras `Model` object. The `czmodel` library will implicitly load the model from the provided path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRUjfIherEEH"
   },
   "source": [
    "The `czmodel` library also provides a `convert_from_json_spec` function that accepts a JSON file with the above mentioned meta data behind the key `ModelMetadata` which will implicitly be deserialized into a `ModelMetadata` object, the model path and optionally a license file:\n",
    "```json\n",
    "{\n",
    "    \"ModelMetadata\": {\n",
    "        \"Type\": \"Regression\",\n",
    "        \"InputShape\": [1024, 1024, 1],\n",
    "        \"OutputShape\": [1024, 1024, 1],\n",
    "        \"ModelName\": \"Regression Model From JSON\",\n",
    "        \"MinOverlap\": [8, 8]\n",
    "    },\n",
    "    \"ModelPath\": \"./saved_tf2_model_output/\",\n",
    "    \"LicenseFile\": null\n",
    "}\n",
    "```\n",
    "\n",
    "This information can be copied to a file e.g. in the current working directory `./model_conversion_spec.json` that also contains the trained model in SavedModel format e.g. generated by the following line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T99UCANrrEEH"
   },
   "outputs": [],
   "source": [
    "# save the trained TF2.SavedModel as a folder structure\n",
    "# The folder + the JSON file can be also used to import the model in ZEN\n",
    "\n",
    "model.save('./saved_tf2_model_output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhDdKxxlrEEH",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fc04f599-6611-4757-ff15-061aa7568a4c",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# This is an additional way to create a CZANN from a saved TF2 model on disk + JSON file.\n",
    "# The currently recommended way to to create the CZANN directly by using czmodel.convert_from_model_spec\n",
    "# the path to the TF2.SavedModel folder is defined in the JSON shown above\n",
    "\n",
    "DefaultConverter().convert_from_json_spec(\n",
    "    model_spec_path='regression_conversion_spec.json',\n",
    "    output_path='./',\n",
    "    output_name = 'simple_kidney_regmodel_from_json',\n",
    "    spatial_dims=(input_size, input_size),\n",
    "    preprocessing=preprocessing,\n",
    "    postprocessing=postprocessing\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bu-S1tg_Asxi"
   },
   "source": [
    "Use the commands below from a terminal to present the notebook as a slideshow.\n",
    "\n",
    "`\n",
    "jupyter nbconvert Regression.ipynb --to slides --post serve \n",
    "    --SlidesExporter.reveal_theme=serif \n",
    "    --SlidesExporter.reveal_scroll=True \n",
    "    --SlidesExporter.reveal_transition=none\n",
    "`"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "-JtOarJOrEEG"
   ],
   "name": "Regresssion_3_0_0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}